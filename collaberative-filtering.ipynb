{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815485e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as npy\n",
    "from scipy.stats import linregress\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import time\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "import os\n",
    "import gc\n",
    "plt.rcParams['figure.dpi'] = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539db918",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = pd.read_feather(\"boardgamegeek.feather\")\n",
    "np = pd.read_feather(\"netflix_prize.feather\")\n",
    "m = pd.read_feather(\"movielens_25m.feather\") \n",
    "y = pd.read_feather(\"yahoo_r2_songs.subsampled.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47572a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rautm\\AppData\\Local\\Temp\\ipykernel_17772\\1849294058.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['user_id'] = train_data['user_id'].map(item_id_map)\n",
      "C:\\Users\\rautm\\AppData\\Local\\Temp\\ipykernel_17772\\1849294058.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['user_id'] = filtered_data['user_id'].map(item_id_map)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>NearestNeighbors</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_neighbors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_neighbors&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('radius',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">radius&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('algorithm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">algorithm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('leaf_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">leaf_size&nbsp;</td>\n",
       "            <td class=\"value\">30</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cosine&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('p',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">p&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('metric_params',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">metric_params&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_jobs=-1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg = bg[bg['user_id'].notnull()]\n",
    "\n",
    "\n",
    "unique_items = bg['item_id'].unique()\n",
    "item_id_map = {old: new for new, old in enumerate(unique_items)}\n",
    "bg['item_id'] = bg['item_id'].map(item_id_map)\n",
    "n_items = len(unique_items)\n",
    "\n",
    "groups = bg['user_id']\n",
    "gss = GroupShuffleSplit(n_splits=1,test_size=0.25,random_state=42)\n",
    "\n",
    "train_idx,test_idx = next(gss.split(bg,groups=groups))\n",
    "\n",
    "train_data = bg.iloc[train_idx]\n",
    "test_data = bg.iloc[test_idx]\n",
    "\n",
    "unique_items = train_data['user_id'].unique()\n",
    "item_id_map = {old: new for new, old in enumerate(unique_items)}\n",
    "train_data['user_id'] = train_data['user_id'].map(item_id_map)\n",
    "\n",
    "n_training_users = len(unique_items)\n",
    "\n",
    "training_X = sparse.csr_matrix((train_data[\"rating\"],\n",
    "                                (train_data[\"user_id\"],\n",
    "                                train_data[\"item_id\"])),\n",
    "                                shape=(n_training_users, n_items))\n",
    "\n",
    "user_counts = test_data['user_id'].value_counts()\n",
    "valid_users = user_counts[user_counts >= 2].index\n",
    "filtered_data = test_data[test_data['user_id'].isin(valid_users)]\n",
    "\n",
    "unique_items = filtered_data['user_id'].unique()\n",
    "item_id_map = {old: new for new, old in enumerate(unique_items)}\n",
    "filtered_data['user_id'] = filtered_data['user_id'].map(item_id_map)\n",
    "\n",
    "test_seen, test_unseen = train_test_split(\n",
    "    filtered_data,\n",
    "    test_size=0.25,\n",
    "    stratify=filtered_data['user_id'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "n_testing_users = test_seen['user_id'].nunique()\n",
    "\n",
    "testing_X = sparse.csr_matrix((test_seen[\"rating\"],\n",
    "                                (test_seen[\"user_id\"],\n",
    "                                test_seen[\"item_id\"])),\n",
    "                                shape=(n_testing_users, n_items))\n",
    "\n",
    "# try k for 5, 10, 25, 50, 100, 150, 250, 350, 500\n",
    "k = 5  \n",
    "nn_model = NearestNeighbors(n_neighbors=k, metric='cosine',n_jobs=-1)\n",
    "nn_model.fit(training_X)\n",
    "\n",
    "\n",
    "distances, indices = nn_model.kneighbors(testing_X)\n",
    "\n",
    "test_users = []\n",
    "neighbor_users = []\n",
    "\n",
    "\n",
    "for test_user_idx, neighbor_indices in enumerate(indices):\n",
    "    test_users.extend([test_user_idx] * len(neighbor_indices))\n",
    "    neighbor_users.extend(neighbor_indices)\n",
    "neighbors_df = pd.DataFrame({\n",
    "    'test_user_id': test_users,\n",
    "    'neighbor_user_id': neighbor_users\n",
    "})\n",
    "\n",
    "merged = neighbors_df.merge(train_data, left_on='neighbor_user_id', right_on='user_id', how='inner')\n",
    "\n",
    "result = (merged.groupby(['test_user_id', 'item_id'])['rating']\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .rename(columns={'test_user_id': 'user_id', 'rating': 'avg_rating'}))\n",
    "\n",
    "k_avg_ratings = test_unseen.merge(result, how = 'left', on = ['item_id','user_id'])\n",
    "\n",
    "k_avg_ratings.to_feather(\"knn/results/bg/5_nn.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4df489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_name, data, k_values, base_output_dir=\"knn/results\"):\n",
    "    \"\"\"\n",
    "    Process a single dataset with multiple k values\n",
    "    Uses chunking for memory-efficient average rating calculation\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing dataset: {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    dataset_start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Data preprocessing\n",
    "        print(f\"Preprocessing {dataset_name}...\")\n",
    "        data = data[data['user_id'].notnull()]\n",
    "        \n",
    "        # Map item IDs to continuous range\n",
    "        unique_items = data['item_id'].unique()\n",
    "        item_id_map = {old: new for new, old in enumerate(unique_items)}\n",
    "        data['item_id'] = data['item_id'].map(item_id_map)\n",
    "        n_items = len(unique_items)\n",
    "        \n",
    "        # Split data\n",
    "        groups = data['user_id']\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "        train_idx, test_idx = next(gss.split(data, groups=groups))\n",
    "        \n",
    "        train_data = data.iloc[train_idx]\n",
    "        test_data = data.iloc[test_idx]\n",
    "        \n",
    "        # Map user IDs for training data\n",
    "        unique_users = train_data['user_id'].unique()\n",
    "        user_id_map = {old: new for new, old in enumerate(unique_users)}\n",
    "        train_data['user_id'] = train_data['user_id'].map(user_id_map)\n",
    "        n_training_users = len(unique_users)\n",
    "        \n",
    "        # Create training matrix\n",
    "        training_X = sparse.csr_matrix((train_data[\"rating\"],\n",
    "                                      (train_data[\"user_id\"],\n",
    "                                       train_data[\"item_id\"])),\n",
    "                                      shape=(n_training_users, n_items))\n",
    "        \n",
    "        # Filter test data for users with at least 2 ratings\n",
    "        user_counts = test_data['user_id'].value_counts()\n",
    "        valid_users = user_counts[user_counts >= 2].index\n",
    "        filtered_data = test_data[test_data['user_id'].isin(valid_users)]\n",
    "        \n",
    "        # Map user IDs for test data\n",
    "        unique_test_users = filtered_data['user_id'].unique()\n",
    "        test_user_id_map = {old: new for new, old in enumerate(unique_test_users)}\n",
    "        filtered_data['user_id'] = filtered_data['user_id'].map(test_user_id_map)\n",
    "        \n",
    "        # Split test data into seen and unseen\n",
    "        test_seen, test_unseen = train_test_split(\n",
    "            filtered_data,\n",
    "            test_size=0.25,\n",
    "            stratify=filtered_data['user_id'],\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        n_testing_users = test_seen['user_id'].nunique()\n",
    "        \n",
    "        # Create testing matrix\n",
    "        testing_X = sparse.csr_matrix((test_seen[\"rating\"],\n",
    "                                     (test_seen[\"user_id\"],\n",
    "                                      test_seen[\"item_id\"])),\n",
    "                                     shape=(n_testing_users, n_items))\n",
    "        \n",
    "        print(f\"Dataset {dataset_name} preprocessed successfully\")\n",
    "        print(f\"Training users: {n_training_users}, Testing users: {n_testing_users}, Items: {n_items}\")\n",
    "        \n",
    "        # Process each k value\n",
    "        for k in k_values:\n",
    "            # Check if output file already exists\n",
    "            output_dir = Path(base_output_dir) / dataset_name\n",
    "            output_file = output_dir / f\"{k}_nn.feather\"\n",
    "            \n",
    "            if output_file.exists():\n",
    "                print(f\"Skipping k={k} for {dataset_name} - file already exists: {output_file}\")\n",
    "                continue\n",
    "            \n",
    "            k_start_time = time.time()\n",
    "            try:\n",
    "                print(f\"\\nProcessing k={k} for {dataset_name}...\")\n",
    "                \n",
    "                # Ensure output directory exists\n",
    "                output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                # Fit KNN model\n",
    "                nn_model = NearestNeighbors(n_neighbors=k, metric='cosine', n_jobs=-1)\n",
    "                nn_model.fit(training_X)\n",
    "                \n",
    "                # Find neighbors\n",
    "                distances, indices = nn_model.kneighbors(testing_X)\n",
    "                \n",
    "                # Memory-efficient processing with chunking by test users\n",
    "                print(f\"Processing neighbors in chunks by test users to manage memory...\")\n",
    "                \n",
    "               # Initialize result accumulator\n",
    "                all_results = []\n",
    "                initial_chunk_size = 5000  # Starting chunk size\n",
    "                min_chunk_size = 100       # Minimum chunk size before giving up\n",
    "                chunk_size = initial_chunk_size\n",
    "                n_test_users = len(indices)\n",
    "\n",
    "                # Process test users in chunks with dynamic sizing\n",
    "                chunk_start = 0\n",
    "                while chunk_start < n_test_users:\n",
    "                    try:\n",
    "                        chunk_end = min(chunk_start + chunk_size, n_test_users)\n",
    "                        \n",
    "                        # Create neighbors dataframe for this chunk of test users\n",
    "                        chunk_test_users = []\n",
    "                        chunk_neighbor_users = []\n",
    "                        \n",
    "                        for test_user_idx in range(chunk_start, chunk_end):\n",
    "                            neighbor_indices = indices[test_user_idx]\n",
    "                            chunk_test_users.extend([test_user_idx] * len(neighbor_indices))\n",
    "                            chunk_neighbor_users.extend(neighbor_indices)\n",
    "                        \n",
    "                        if not chunk_test_users:  # Skip empty chunks\n",
    "                            chunk_start = chunk_end\n",
    "                            continue\n",
    "                        \n",
    "                        # Create neighbors dataframe for this chunk\n",
    "                        chunk_neighbors_df = pd.DataFrame({\n",
    "                            'test_user_id': chunk_test_users,\n",
    "                            'neighbor_user_id': chunk_neighbor_users\n",
    "                        })\n",
    "                        \n",
    "                        # Merge with training data\n",
    "                        chunk_merged = chunk_neighbors_df.merge(\n",
    "                            train_data, \n",
    "                            left_on='neighbor_user_id', \n",
    "                            right_on='user_id', \n",
    "                            how='inner'\n",
    "                        )\n",
    "                        \n",
    "                        # Calculate average ratings for this chunk of test users\n",
    "                        chunk_result = (chunk_merged.groupby(['test_user_id', 'item_id'])['rating']\n",
    "                                    .mean()\n",
    "                                    .reset_index()\n",
    "                                    .rename(columns={'test_user_id': 'user_id', 'rating': 'avg_rating'}))\n",
    "                        \n",
    "                        all_results.append(chunk_result)\n",
    "                        \n",
    "                        # Clean up chunk data to free memory\n",
    "                        del chunk_neighbors_df, chunk_merged, chunk_result\n",
    "                        \n",
    "                        # Successfully processed chunk, move to next\n",
    "                        chunk_start = chunk_end\n",
    "                        \n",
    "                        # Reset chunk size to initial size after successful processing\n",
    "                        # (in case it was reduced due to previous memory errors)\n",
    "                        if chunk_size < initial_chunk_size:\n",
    "                            chunk_size = min(initial_chunk_size, chunk_size * 2)  # Gradually increase back\n",
    "                        \n",
    "                        if chunk_end % 5000 == 0 or chunk_end == n_test_users:\n",
    "                            print(f\"Processed {chunk_end}/{n_test_users} test users (chunk_size={chunk_size})\")\n",
    "                    \n",
    "                    except MemoryError as e:\n",
    "                        print(f\"MEMORY ERROR with chunk_size={chunk_size}: {str(e)}\")\n",
    "                        \n",
    "                        # Clean up any partially created variables\n",
    "                        if 'chunk_neighbors_df' in locals():\n",
    "                            del chunk_neighbors_df\n",
    "                        if 'chunk_merged' in locals():\n",
    "                            del chunk_merged\n",
    "                        if 'chunk_result' in locals():\n",
    "                            del chunk_result\n",
    "                        \n",
    "                        # Force garbage collection\n",
    "                        gc.collect()\n",
    "                        \n",
    "                        # Reduce chunk size\n",
    "                        new_chunk_size = max(chunk_size // 2, min_chunk_size)\n",
    "                        \n",
    "                        if new_chunk_size < min_chunk_size:\n",
    "                            print(f\"Chunk size would be below minimum ({min_chunk_size}). Cannot continue processing.\")\n",
    "                            break\n",
    "                        \n",
    "                        print(f\"Reducing chunk_size from {chunk_size} to {new_chunk_size}\")\n",
    "                        chunk_size = new_chunk_size\n",
    "                        \n",
    "                        # Don't increment chunk_start - retry the same chunk with smaller size\n",
    "                        continue\n",
    "\n",
    "                # Combine all chunk results (no additional aggregation needed)\n",
    "                if all_results:\n",
    "                    result = pd.concat(all_results, ignore_index=True)\n",
    "                    del all_results  # Free memory\n",
    "                else:\n",
    "                    result = pd.DataFrame(columns=['user_id', 'item_id', 'avg_rating'])\n",
    "\n",
    "                # return test_unseen,result,all_results\n",
    "                # Merge with test_unseen\n",
    "                k_avg_ratings = test_unseen.merge(result, how='left', on=['item_id', 'user_id'])\n",
    "\n",
    "                # Save results\n",
    "                k_avg_ratings.to_feather(output_file)\n",
    "\n",
    "                # Force garbage collection after each k value\n",
    "                gc.collect()\n",
    "\n",
    "                k_end_time = time.time()\n",
    "                k_duration = k_end_time - k_start_time\n",
    "                print(f\"k={k} completed in {k_duration:.2f} seconds\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"ERROR processing k={k} for {dataset_name}: {str(e)}\")\n",
    "                print(f\"Traceback: {traceback.format_exc()}\")\n",
    "                continue\n",
    "        \n",
    "        dataset_end_time = time.time()\n",
    "        dataset_duration = dataset_end_time - dataset_start_time\n",
    "        print(f\"\\nDataset {dataset_name} completed in {dataset_duration:.2f} seconds ({dataset_duration/60:.2f} minutes)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR processing dataset {dataset_name}: {str(e)}\")\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "        dataset_end_time = time.time()\n",
    "        dataset_duration = dataset_end_time - dataset_start_time\n",
    "        print(f\"Dataset {dataset_name} failed after {dataset_duration:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b48167b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting KNN processing for all datasets\n",
      "K values to process: [5, 10, 25, 50, 100, 150, 250, 350, 500]\n",
      "Total datasets: 4\n",
      "Note: Will skip processing if output file already exists\n",
      "\n",
      "Loading dataset: boardgamegeek.feather\n",
      "Dataset loaded successfully. Shape: (18942215, 3)\n",
      "\n",
      "============================================================\n",
      "Processing dataset: bg\n",
      "============================================================\n",
      "Preprocessing bg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rautm\\AppData\\Local\\Temp\\ipykernel_23216\\1553491376.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['item_id'] = data['item_id'].map(item_id_map)\n",
      "C:\\Users\\rautm\\AppData\\Local\\Temp\\ipykernel_23216\\1553491376.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['user_id'] = train_data['user_id'].map(user_id_map)\n",
      "C:\\Users\\rautm\\AppData\\Local\\Temp\\ipykernel_23216\\1553491376.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['user_id'] = filtered_data['user_id'].map(test_user_id_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bg preprocessed successfully\n",
      "Training users: 308530, Testing users: 83026, Items: 21925\n",
      "\n",
      "Processing k=5 for bg...\n",
      "Processing neighbors in chunks by test users to manage memory...\n",
      "Processed 5000/83026 test users (chunk_size=5000)\n",
      "Processed 10000/83026 test users (chunk_size=5000)\n",
      "Processed 15000/83026 test users (chunk_size=5000)\n",
      "Processed 20000/83026 test users (chunk_size=5000)\n",
      "Processed 25000/83026 test users (chunk_size=5000)\n",
      "Processed 30000/83026 test users (chunk_size=5000)\n",
      "Processed 35000/83026 test users (chunk_size=5000)\n",
      "Processed 40000/83026 test users (chunk_size=5000)\n",
      "Processed 45000/83026 test users (chunk_size=5000)\n",
      "Processed 50000/83026 test users (chunk_size=5000)\n",
      "Processed 55000/83026 test users (chunk_size=5000)\n",
      "Processed 60000/83026 test users (chunk_size=5000)\n",
      "Processed 65000/83026 test users (chunk_size=5000)\n",
      "Processed 70000/83026 test users (chunk_size=5000)\n",
      "Processed 75000/83026 test users (chunk_size=5000)\n",
      "Processed 80000/83026 test users (chunk_size=5000)\n",
      "Processed 83026/83026 test users (chunk_size=5000)\n",
      "k=5 completed in 482.37 seconds\n",
      "\n",
      "Processing k=10 for bg...\n",
      "Processing neighbors in chunks by test users to manage memory...\n",
      "Processed 5000/83026 test users (chunk_size=5000)\n",
      "Processed 10000/83026 test users (chunk_size=5000)\n",
      "Processed 15000/83026 test users (chunk_size=5000)\n",
      "Processed 20000/83026 test users (chunk_size=5000)\n",
      "Processed 25000/83026 test users (chunk_size=5000)\n",
      "Processed 30000/83026 test users (chunk_size=5000)\n",
      "Processed 35000/83026 test users (chunk_size=5000)\n",
      "Processed 40000/83026 test users (chunk_size=5000)\n",
      "Processed 45000/83026 test users (chunk_size=5000)\n",
      "Processed 50000/83026 test users (chunk_size=5000)\n",
      "Processed 55000/83026 test users (chunk_size=5000)\n",
      "Processed 60000/83026 test users (chunk_size=5000)\n",
      "Processed 65000/83026 test users (chunk_size=5000)\n",
      "Processed 70000/83026 test users (chunk_size=5000)\n",
      "Processed 75000/83026 test users (chunk_size=5000)\n",
      "Processed 80000/83026 test users (chunk_size=5000)\n",
      "Processed 83026/83026 test users (chunk_size=5000)\n",
      "k=10 completed in 484.37 seconds\n",
      "\n",
      "Processing k=25 for bg...\n",
      "Processing neighbors in chunks by test users to manage memory...\n",
      "Processed 5000/83026 test users (chunk_size=5000)\n",
      "Processed 10000/83026 test users (chunk_size=5000)\n",
      "Processed 15000/83026 test users (chunk_size=5000)\n",
      "Processed 20000/83026 test users (chunk_size=5000)\n",
      "Processed 25000/83026 test users (chunk_size=5000)\n",
      "Processed 30000/83026 test users (chunk_size=5000)\n",
      "Processed 35000/83026 test users (chunk_size=5000)\n",
      "Processed 40000/83026 test users (chunk_size=5000)\n",
      "Processed 45000/83026 test users (chunk_size=5000)\n",
      "Processed 50000/83026 test users (chunk_size=5000)\n",
      "Processed 55000/83026 test users (chunk_size=5000)\n",
      "Processed 60000/83026 test users (chunk_size=5000)\n",
      "Processed 65000/83026 test users (chunk_size=5000)\n",
      "Processed 70000/83026 test users (chunk_size=5000)\n",
      "Processed 75000/83026 test users (chunk_size=5000)\n",
      "Processed 80000/83026 test users (chunk_size=5000)\n",
      "Processed 83026/83026 test users (chunk_size=5000)\n",
      "k=25 completed in 491.83 seconds\n",
      "\n",
      "Processing k=50 for bg...\n",
      "Processing neighbors in chunks by test users to manage memory...\n",
      "Processed 5000/83026 test users (chunk_size=5000)\n",
      "Processed 10000/83026 test users (chunk_size=5000)\n",
      "Processed 15000/83026 test users (chunk_size=5000)\n",
      "Processed 20000/83026 test users (chunk_size=5000)\n",
      "Processed 25000/83026 test users (chunk_size=5000)\n",
      "Processed 30000/83026 test users (chunk_size=5000)\n",
      "Processed 35000/83026 test users (chunk_size=5000)\n",
      "Processed 40000/83026 test users (chunk_size=5000)\n",
      "Processed 45000/83026 test users (chunk_size=5000)\n",
      "Processed 50000/83026 test users (chunk_size=5000)\n",
      "Processed 55000/83026 test users (chunk_size=5000)\n",
      "Processed 60000/83026 test users (chunk_size=5000)\n",
      "Processed 65000/83026 test users (chunk_size=5000)\n",
      "Processed 70000/83026 test users (chunk_size=5000)\n",
      "Processed 75000/83026 test users (chunk_size=5000)\n",
      "Processed 80000/83026 test users (chunk_size=5000)\n",
      "Processed 83026/83026 test users (chunk_size=5000)\n",
      "k=50 completed in 509.66 seconds\n",
      "\n",
      "Processing k=100 for bg...\n",
      "Processing neighbors in chunks by test users to manage memory...\n",
      "Processed 5000/83026 test users (chunk_size=5000)\n",
      "Processed 10000/83026 test users (chunk_size=5000)\n",
      "Processed 15000/83026 test users (chunk_size=5000)\n",
      "Processed 20000/83026 test users (chunk_size=5000)\n",
      "Processed 25000/83026 test users (chunk_size=5000)\n",
      "Processed 30000/83026 test users (chunk_size=5000)\n",
      "Processed 35000/83026 test users (chunk_size=5000)\n",
      "Processed 40000/83026 test users (chunk_size=5000)\n",
      "Processed 45000/83026 test users (chunk_size=5000)\n",
      "Processed 50000/83026 test users (chunk_size=5000)\n",
      "Processed 55000/83026 test users (chunk_size=5000)\n",
      "Processed 60000/83026 test users (chunk_size=5000)\n",
      "Processed 65000/83026 test users (chunk_size=5000)\n",
      "Processed 70000/83026 test users (chunk_size=5000)\n",
      "Processed 75000/83026 test users (chunk_size=5000)\n",
      "Processed 80000/83026 test users (chunk_size=5000)\n",
      "Processed 83026/83026 test users (chunk_size=5000)\n",
      "k=100 completed in 577.62 seconds\n",
      "\n",
      "Processing k=150 for bg...\n",
      "Processing neighbors in chunks by test users to manage memory...\n",
      "Processed 5000/83026 test users (chunk_size=5000)\n",
      "Processed 10000/83026 test users (chunk_size=5000)\n",
      "Processed 15000/83026 test users (chunk_size=5000)\n",
      "Processed 20000/83026 test users (chunk_size=5000)\n",
      "Processed 25000/83026 test users (chunk_size=5000)\n",
      "Processed 30000/83026 test users (chunk_size=5000)\n",
      "Processed 35000/83026 test users (chunk_size=5000)\n",
      "Processed 40000/83026 test users (chunk_size=5000)\n",
      "Processed 45000/83026 test users (chunk_size=5000)\n",
      "Processed 50000/83026 test users (chunk_size=5000)\n",
      "Processed 55000/83026 test users (chunk_size=5000)\n",
      "Processed 60000/83026 test users (chunk_size=5000)\n",
      "Processed 65000/83026 test users (chunk_size=5000)\n",
      "Processed 70000/83026 test users (chunk_size=5000)\n",
      "Processed 75000/83026 test users (chunk_size=5000)\n",
      "Processed 80000/83026 test users (chunk_size=5000)\n",
      "Processed 83026/83026 test users (chunk_size=5000)\n",
      "k=150 completed in 670.15 seconds\n",
      "\n",
      "Processing k=250 for bg...\n",
      "Processing neighbors in chunks by test users to manage memory...\n",
      "MEMORY ERROR with chunk_size=5000: Unable to allocate 4.61 GiB for an array with shape (2, 309461901) and data type int64\n",
      "Reducing chunk_size from 5000 to 2500\n",
      "MEMORY ERROR with chunk_size=2500: Unable to allocate 1.38 GiB for an array with shape (184937779,) and data type int64\n",
      "Reducing chunk_size from 2500 to 1250\n",
      "Processed 83026/83026 test users (chunk_size=5000)\n",
      "k=250 completed in 1006.14 seconds\n",
      "\n",
      "Processing k=350 for bg...\n",
      "Processing neighbors in chunks by test users to manage memory...\n",
      "MEMORY ERROR with chunk_size=5000: Unable to allocate 3.20 GiB for an array with shape (1, 429211741) and data type int64\n",
      "Reducing chunk_size from 5000 to 2500\n",
      "MEMORY ERROR with chunk_size=2500: Unable to allocate 1.90 GiB for an array with shape (255279821,) and data type int64\n",
      "Reducing chunk_size from 2500 to 1250\n",
      "Processed 83026/83026 test users (chunk_size=5000)\n",
      "k=350 completed in 1287.07 seconds\n",
      "\n",
      "Processing k=500 for bg...\n",
      "Processing neighbors in chunks by test users to manage memory...\n",
      "MEMORY ERROR with chunk_size=5000: Unable to allocate 4.51 GiB for an array with shape (605629394, 1) and data type int64\n",
      "Reducing chunk_size from 5000 to 2500\n",
      "MEMORY ERROR with chunk_size=2500: Unable to allocate 2.67 GiB for an array with shape (358315825, 1) and data type int64\n",
      "Reducing chunk_size from 2500 to 1250\n",
      "MEMORY ERROR with chunk_size=1250: Unable to allocate 2.95 GiB for an array with shape (2, 197666560) and data type int64\n",
      "Reducing chunk_size from 1250 to 625\n",
      "MEMORY ERROR with chunk_size=1250: Unable to allocate 1.30 GiB for an array with shape (1, 174134877) and data type int64\n",
      "Reducing chunk_size from 1250 to 625\n",
      "MEMORY ERROR with chunk_size=2500: Unable to allocate 1.84 GiB for an array with shape (1, 247313569) and data type float64\n",
      "Reducing chunk_size from 2500 to 1250\n",
      "MEMORY ERROR with chunk_size=1250: Unable to allocate 2.08 GiB for an array with shape (2, 139513117) and data type int64\n",
      "Reducing chunk_size from 1250 to 625\n",
      "MEMORY ERROR with chunk_size=2500: Unable to allocate 3.08 GiB for an array with shape (2, 206786315) and data type int64\n",
      "Reducing chunk_size from 2500 to 1250\n",
      "MEMORY ERROR with chunk_size=2500: Unable to allocate 1.40 GiB for an array with shape (1, 188201761) and data type int64\n",
      "Reducing chunk_size from 2500 to 1250\n",
      "MEMORY ERROR with chunk_size=2500: Unable to allocate 2.40 GiB for an array with shape (2, 161360006) and data type int64\n",
      "Reducing chunk_size from 2500 to 1250\n",
      "MEMORY ERROR with chunk_size=2500: Unable to allocate 2.10 GiB for an array with shape (2, 141006477) and data type int64\n",
      "Reducing chunk_size from 2500 to 1250\n",
      "MEMORY ERROR with chunk_size=5000: Unable to allocate 1.69 GiB for an array with shape (1, 226387638) and data type int64\n",
      "Reducing chunk_size from 5000 to 2500\n",
      "MEMORY ERROR with chunk_size=5000: Unable to allocate 1.52 GiB for an array with shape (1, 204524624) and data type int64\n",
      "Reducing chunk_size from 5000 to 2500\n",
      "MEMORY ERROR with chunk_size=5000: Unable to allocate 2.44 GiB for an array with shape (2, 163417747) and data type int64\n",
      "Reducing chunk_size from 5000 to 2500\n",
      "MEMORY ERROR with chunk_size=5000: Unable to allocate 2.24 GiB for an array with shape (2, 150401642) and data type int64\n",
      "Reducing chunk_size from 5000 to 2500\n",
      "Processed 83026/83026 test users (chunk_size=5000)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Main function to process all datasets\n",
    "\"\"\"\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Define datasets\n",
    "datasets = {\n",
    "    'bg': 'boardgamegeek.feather',\n",
    "    'np': 'netflix_prize.feather',\n",
    "    'm': 'movielens_25m.feather',\n",
    "    'y': 'yahoo_r2_songs.subsampled.feather'\n",
    "}\n",
    "\n",
    "# Define k values to try\n",
    "k_values = [5, 10, 25, 50, 100, 150, 250, 350, 500]\n",
    "\n",
    "print(\"Starting KNN processing for all datasets\")\n",
    "print(f\"K values to process: {k_values}\")\n",
    "print(f\"Total datasets: {len(datasets)}\")\n",
    "print(\"Note: Will skip processing if output file already exists\")\n",
    "\n",
    "# Process each dataset\n",
    "for dataset_name, filename in datasets.items():\n",
    "    try:\n",
    "        print(f\"\\nLoading dataset: {filename}\")\n",
    "        data = pd.read_feather(filename)\n",
    "        print(f\"Dataset loaded successfully. Shape: {data.shape}\")\n",
    "        \n",
    "        test_unseen,result,all_results = process_dataset(dataset_name, data, k_values)\n",
    "        # break\n",
    "        # Force garbage collection between datasets\n",
    "        del data\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR loading dataset {filename}: {str(e)}\")\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "        gc.collect()\n",
    "        continue\n",
    "    # break\n",
    "\n",
    "total_end_time = time.time()\n",
    "total_duration = total_end_time - total_start_time\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ALL PROCESSING COMPLETED\")\n",
    "print(f\"Total runtime: {total_duration:.2f} seconds ({total_duration/60:.2f} minutes, {total_duration/3600:.2f} hours)\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
